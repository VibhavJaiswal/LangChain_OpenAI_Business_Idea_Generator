{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from secret_key import openapi_key\n",
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211517ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Maharaja's Palace\"\n"
     ]
    }
   ],
   "source": [
    "# llm = OpenAI(temperature = .1,max_tokens=150,\n",
    "#     top_p=0.85,\n",
    "#     frequency_penalty=0.4,\n",
    "#     presence_penalty=0.3)\n",
    "llm = OpenAI(temperature = 0.4)\n",
    "name = llm(\"I want to open a restaurant for indian food. Suggest a royal name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a780b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d3c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step. Finish the answer in 25 words\"\"\"\n",
    "\n",
    "prompt_template_name1 = PromptTemplate(template=template, input_variables=[\"answer the question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db257e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_chain2 = LLMChain(prompt=prompt_template_name1, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7fb9209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nArtificial intelligence (AI) has its roots in ancient Greek mythology, but the modern field began in the 1950s with the development of computer science and the concept of intelligent machines. Since then, AI has gone through periods of hype and disappointment, but has made significant advancements in areas such as natural language processing, computer vision, and machine learning. Today, AI is used in a variety of applications, from virtual assistants to self-driving cars, and continues to evolve and shape our world.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "question = \"Provide a brief overview of the history of artificial intelligence.\"\n",
    "\n",
    "llm_chain2.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd5a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c89f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1\n",
    "prompt_template_name=PromptTemplate(input_variables=[\"cuisine\"],\n",
    "                                    template=\"i want to open a restaurant for this {cuisine}, suggest a fancy name for it\")\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name,output_key=\"restaurant_name\")\n",
    " \n",
    "# Prompt 2\n",
    "prompt_templates_items=PromptTemplate(input_variables=[\"restaurant_name\"],\n",
    "                                      template=\"suggest 3 fancy and unique menu items for this {restaurant_name}\")\n",
    "food_items_chain=LLMChain(llm=llm,prompt=prompt_templates_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daec4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(\n",
    "    chains=[name_chain, food_items_chain], input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\", \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f43539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'North Indian',\n",
       " 'restaurant_name': '\\n\\n\"Royal Spice Bistro\" ',\n",
       " 'menu_items': '\\n\\n1. \"Saffron-infused Lobster Bisque\": A rich and creamy soup made with fresh lobster, infused with the delicate flavors of saffron and finished with a touch of cream. Served with a side of warm, homemade bread for dipping.\\n\\n2. \"Truffle and Wild Mushroom Risotto\": Creamy Arborio rice cooked to perfection with a medley of wild mushrooms and finished with a drizzle of truffle oil. Topped with shaved Parmesan cheese and fresh herbs for a luxurious and earthy flavor.\\n\\n3. \"Spiced Lamb Shank with Pomegranate Glaze\": Tender and juicy lamb shank slow-cooked in a blend of aromatic spices and finished with a tangy pomegranate glaze. Served with a side of fluffy couscous and roasted vegetables for a burst of flavors in every bite.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\": \"North Indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d7c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Template\n",
    "prompt_template_name = PromptTemplate(input_variables=[\"industry\"],\n",
    "                                    template = \"I want to start a startup for {industry} , suggest me a good name for this\")\n",
    "\n",
    "name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
    "\n",
    "# Second Template\n",
    "prompt_template_items = PromptTemplate( input_variables = [\"name\"],\n",
    "                                     template = \"suggest 3 business strategies in bullet points for {name}\")\n",
    "\n",
    "strategies_chain = LLMChain(llm = llm, prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbf9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains=[name_chain, strategies_chain]) # This gives us one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfc1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Expand services to include last-mile delivery: By offering last-mile delivery services, SwiftHaul Logistics can tap into the growing e-commerce market and reach a wider range of customers. This can also help differentiate the company from competitors and attract new clients.\n",
      "\n",
      "2. Invest in technology and automation: In order to stay competitive and improve efficiency, SwiftHaul Logistics should invest in technology and automation. This can include implementing a transportation management system, using GPS tracking for real-time updates, and automating administrative tasks. This will not only improve operations but also enhance the customer experience.\n",
      "\n",
      "3. Form strategic partnerships: Collaborating with other logistics companies, suppliers, and distributors can help SwiftHaul Logistics expand its reach and offer more comprehensive services to clients. By forming strategic partnerships, the company can also gain access to new markets and resources, while reducing costs and risks. \n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"logistics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61682f",
   "metadata": {},
   "source": [
    "## Define a Function to Get Completion__\n",
    "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
    "\n",
    "__Parameters:__\n",
    "\n",
    "- __prompt__: It is the text input for which the model will generate a completion.\n",
    "- __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
    "\n",
    "The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.\n",
    "\n",
    "This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bc61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    # Create the messages list with the user prompt\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Create a chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # Degree of randomness in the model's output\n",
    "    )\n",
    "    \n",
    "    # Return the content of the first response\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac6aea",
   "metadata": {},
   "source": [
    "# Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58675d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Salut, bonjour !\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English sentence to French:\n",
    "\n",
    "'Hey, Good Morning!'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14958bce",
   "metadata": {},
   "source": [
    "# One Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63457215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Q: What is the capital of Italy?\n",
    "A: \"\"Imperium Romanum in aeternum stabit.\", Rome\n",
    "\n",
    "Q: What is the capital of India?\n",
    "A:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8e9a6",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a6be3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Q: What is the capital of Italy?\n",
    "A: \"\"Imperium Romanum in aeternum stabit.\", Rome\n",
    "\n",
    "Q: What is the capital of France?\n",
    "A:\"L'Empire romain devrait tenir pour l'éternité.\", Paris\n",
    "\n",
    "Q: What is the capital of India?\n",
    "A:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6116a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"भारतीय साम्राज्य सदैव बना रहना चाहिए।\", New Delhi\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Q: What is the capital of Italy?\n",
    "A: \"Imperium Romanum in aeternum stabit.\", Rome\n",
    "\n",
    "Q: What is the capital of France?\n",
    "A: \"L'Empire romain devrait tenir pour l'éternité.\", Paris\n",
    "\n",
    "Q: What is the capital of Japan?\n",
    "A: \"日本は永遠に生き続けるべきです。\", Tokyo\n",
    "\n",
    "Q: What is the capital of Germany?\n",
    "A: \"Das Deutsche Reich sollte für immer bestehen.\", Berlin\n",
    "\n",
    "Q: What is the capital of Brazil?\n",
    "A: \"O Império Brasileiro deve durar para sempre.\", Brasília\n",
    "\n",
    "Q: What is the capital of India?\n",
    "A:\n",
    "\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53cc4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Feedback: \"I loved the quick service and friendly staff.\"\n",
    "Classification: Positive\n",
    "\n",
    "Feedback: \"The product did not meet my expectations.\"\n",
    "Classification: Negative\n",
    "\n",
    "Feedback: \"I am not sure if this is the right product for me.\"\n",
    "Classification: Neutral\n",
    "\n",
    "Feedback: \"Your customer support was helpful, Really happy.\"\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ffd67fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Renew Your Subscription Now!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Task: Generate a subject line for the following emails.\n",
    "\n",
    "Email: \"Thank you for your purchase! Your order has been shipped and will arrive in 3-5 business days.\"\n",
    "Subject: \"Your Order Has Shipped!\"\n",
    "\n",
    "Email: \"We noticed you left items in your cart. Don’t miss out on these great deals!\"\n",
    "Subject: \"Don’t Forget: Items Waiting in Your Cart!\"\n",
    "\n",
    "Email: \"We’ve just launched a new product line. Check out our latest arrivals and get 10% off your first purchase.\"\n",
    "Subject: \"Explore Our New Arrivals & Enjoy 10% Off!\"\n",
    "\n",
    "Email: \"Your subscription is about to expire. Renew now to continue enjoying our services.\"\n",
    "Subject:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098b375",
   "metadata": {},
   "source": [
    "# Sequential or Conversational Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78721b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Imagine you are a detective trying to solve a mystery.\n",
      "Response: As a detective, I am faced with a perplexing mystery that has left the community in fear and confusion. The case involves a series of seemingly random disappearances of young women in the area. The only connection between the victims is that they were all last seen near a local park.\n",
      "\n",
      "I begin my investigation by interviewing witnesses who were in the park around the time of the disappearances. I also review surveillance footage from nearby businesses to see if there are any suspicious individuals or vehicles in the area.\n",
      "\n",
      "As I dig deeper into the case, I discover a pattern in the disappearances - all the victims had recently visited a specific coffee shop in the area. I decide to stake out the coffee shop and observe the customers to see if anyone stands out as a potential suspect.\n",
      "\n",
      "After several days of surveillance, I notice a man who frequents the coffee shop and seems to take an unusual interest in the young women who visit. I follow him discreetly and witness him approaching a young woman who matches the description of the latest missing person.\n",
      "\n",
      "I quickly intervene and apprehend the suspect, who confesses to kidnapping the women and holding them captive in his basement. Thanks to my quick thinking and thorough investigation, I am able to rescue the victims and bring the perpetrator to justice.\n",
      "\n",
      "The community is relieved and grateful for my efforts in solving the mystery and bringing closure to the families of the missing women. As a detective, I take pride in my ability to solve even the most challenging cases and bring peace to those affected by crime.\n",
      "\n",
      "Prompt: You arrive at the crime scene and start looking for clues.\n",
      "Response: You notice a broken window with shards of glass scattered on the ground. There are also muddy footprints leading away from the window. As you follow the footprints, you come across a discarded glove with a distinct logo on it. \n",
      "\n",
      "You take note of the glove and continue to search the area. You find a piece of torn fabric caught on a nearby fence, which appears to match the fabric of the glove. \n",
      "\n",
      "You also notice a small bloodstain on the ground, which you carefully collect for further analysis. \n",
      "\n",
      "As you piece together the evidence, you start to form a theory of what may have happened at the crime scene. You make a mental note to interview any witnesses in the area and to run a background check on the logo found on the glove. \n",
      "\n",
      "With the evidence collected, you head back to the station to begin your investigation and hopefully solve the case.\n",
      "\n",
      "Prompt: You find a strange object at the crime scene. What is it?\n",
      "Response: The strange object found at the crime scene is a small, intricately carved wooden figurine of a mysterious creature with glowing red eyes. It appears to be of ancient origin and emits a faint, eerie energy. Its presence at the crime scene raises more questions than answers, leaving investigators puzzled as to its significance in the case.\n",
      "\n",
      "Prompt: How does this object relate to the crime?\n",
      "Response: Without knowing what the object is or any details about the crime, it is impossible to determine how they may be related. More information would be needed to make a connection between the object and the crime.\n",
      "\n",
      "Prompt: Who do you think is the suspect and why?\n",
      "Response: Without more information about the situation or context, it is impossible to determine who the suspect may be. It is important to gather all relevant evidence and information before making any accusations or assumptions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Imagine you are a detective trying to solve a mystery.\",\n",
    "    \"You arrive at the crime scene and start looking for clues.\",\n",
    "    \"You find a strange object at the crime scene. What is it?\",\n",
    "    \"How does this object relate to the crime?\",\n",
    "    \"Who do you think is the suspect and why?\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b299c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Describe the issue you are experiencing with your device.\n",
      "Response: I am experiencing slow performance and frequent freezing on my device. It takes a long time to open apps or switch between them, and sometimes the device becomes unresponsive and I have to restart it.\n",
      "\n",
      "Prompt: Have you tried restarting your device? If not, please do so and describe what happens.\n",
      "Response: I'm sorry, I am a virtual assistant and do not have the ability to restart physical devices. However, if you are experiencing technical issues with your device, I recommend restarting it to see if that resolves the problem. If you continue to experience issues, please provide more details so I can assist you further.\n",
      "\n",
      "Prompt: What is the model number of your device?\n",
      "Response: I'm sorry, I am a virtual assistant and do not have a physical device. I am here to assist you with any questions or information you may need.\n",
      "\n",
      "Prompt: Based on the model number, these are common issues. Which one matches your problem?\n",
      "Response: I'm sorry, but you did not provide a model number or any specific issues for me to match. Please provide more information so I can assist you better.\n",
      "\n",
      "Prompt: Here are the steps to resolve this issue. Follow them one by one, and let me know if the problem persists.\n",
      "Response: 1. Restart your device: Sometimes a simple restart can resolve many technical issues. Turn off your device, wait a few seconds, and then turn it back on.\n",
      "\n",
      "2. Check your internet connection: Make sure you have a stable internet connection. If you are using Wi-Fi, try restarting your router or connecting to a different network.\n",
      "\n",
      "3. Clear your browser cache: Clearing your browser's cache can help resolve loading issues. Go to your browser settings and clear the cache and cookies.\n",
      "\n",
      "4. Update your browser: Make sure you are using the latest version of your browser. Outdated browsers can sometimes cause loading problems.\n",
      "\n",
      "5. Disable browser extensions: Some browser extensions can interfere with website loading. Try disabling any extensions you have installed and see if that resolves the issue.\n",
      "\n",
      "6. Try a different browser: If the problem persists, try accessing the website using a different browser to see if the issue is specific to your current browser.\n",
      "\n",
      "7. Contact the website support: If none of the above steps resolve the issue, reach out to the website's support team for further assistance. They may be able to provide specific troubleshooting steps for their site.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Describe the issue you are experiencing with your device.\",\n",
    "    \"Have you tried restarting your device? If not, please do so and describe what happens.\",\n",
    "    \"What is the model number of your device?\",\n",
    "    \"Based on the model number, these are common issues. Which one matches your problem?\",\n",
    "    \"Here are the steps to resolve this issue. Follow them one by one, and let me know if the problem persists.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51e45feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Please describe the main symptoms you are experiencing.\n",
      "Response: I'm sorry, but as an AI, I do not have any physical sensations or symptoms. I am here to assist you with any questions or concerns you may have. If you are experiencing symptoms, it is important to consult with a healthcare professional for an accurate diagnosis and appropriate treatment.\n",
      "\n",
      "Prompt: How long have you been experiencing these symptoms?\n",
      "Response: I'm sorry, I am not experiencing any symptoms as I am an AI assistant. How can I assist you today?\n",
      "\n",
      "Prompt: Do you have any pre-existing conditions or allergies?\n",
      "Response: I'm sorry, I am a language model AI and do not have any physical health conditions or allergies.\n",
      "\n",
      "Prompt: Have you traveled recently or come into contact with anyone who is sick?\n",
      "Response: I am an AI and do not have the ability to travel or come into contact with anyone who is sick.\n",
      "\n",
      "Prompt: Based on your symptoms and history, these are potential diagnoses. Which one seems most accurate to you?\n",
      "Response: I'm sorry, but I am not able to provide medical diagnoses as I am just a language model AI. It is important to consult with a healthcare professional for an accurate diagnosis and treatment plan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Please describe the main symptoms you are experiencing.\",\n",
    "    \"How long have you been experiencing these symptoms?\",\n",
    "    \"Do you have any pre-existing conditions or allergies?\",\n",
    "    \"Have you traveled recently or come into contact with anyone who is sick?\",\n",
    "    \"Based on your symptoms and history, these are potential diagnoses. Which one seems most accurate to you?\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = get_completion(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46feac",
   "metadata": {},
   "source": [
    "# Self-Consistency Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "599e2c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 30-pound weight is heavier than 1000 feathers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Let's consider which is heavier: 1000 feathers or a 30-pound weight. I'll think through this in a few different ways and then decide which answer seems most consistent.\n",
    "\n",
    "1. First line of reasoning: A single feather is very light, almost weightless. So, 1000 feathers might still be quite light, possibly lighter than a 30-pound weight.\n",
    "\n",
    "2. Second line of reasoning: 1000 is a large number, and when you add up the weight of so many feathers, it could be quite heavy. Maybe it's heavier than a 30-pound weight.\n",
    "\n",
    "3. Third line of reasoning: The average weight of a feather is very small. Even 1000 feathers would not add up to 30 pounds.\n",
    "\n",
    "Considering these reasonings, the most consistent answer is:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e331fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. First approach:\n",
      "15 - 3 = 12\n",
      "12 + 8 = 20\n",
      "20 - 5 = 15\n",
      "\n",
      "2. Second approach:\n",
      "8 - 5 = 3\n",
      "15 - 3 + 3 = 15\n",
      "\n",
      "3. Third approach:\n",
      "Starting with 15 apples:\n",
      "15 - 3 = 12\n",
      "12 + 8 = 20\n",
      "20 - 5 = 15\n",
      "\n",
      "All three approaches give the same answer of 15 apples. Therefore, the answer is consistent across different methods of solving the problem.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I will solve the following math problem in several different ways and check if I arrive at the same answer each time.\n",
    "\n",
    "Problem: If you have 15 apples and you give away 3, then gain 8 more, and finally lose 5, how many apples do you have?\n",
    "\n",
    "1. First approach: Start by subtracting 3 from 15, then add 8, and subtract 5.\n",
    "\n",
    "2. Second approach: Combine the gains and losses first (8 - 5), then apply the net change to the original number of apples (15 - 3 + net change).\n",
    "\n",
    "3. Third approach: Apply each operation in sequence and keep track of the apples after each step.\n",
    "\n",
    "Let's see which approach gives the most consistent result.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7af76",
   "metadata": {},
   "source": [
    "# Tree-Of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73fd92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "The dimensions should be 40 meters by 20 meters, creating a rectangular field with an area of 800 square meters.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Solve the problem: A farmer has 100 meters of fencing and wants to enclose the maximum area for his rectangular field. What should the dimensions be?\n",
    "\n",
    "Let's think about this in a few ways:\n",
    "\n",
    "1. If the field is a square, each side would be 100 / 4 = 25 meters. The area would be 25 * 25 = 625 square meters.\n",
    "\n",
    "2. What if the field is not a square? Let's try a 2:1 ratio. The lengths would be 40 and 20 meters. The area would be 40 * 20 = 800 square meters.\n",
    "\n",
    "3. Are there any other ratios that might give a larger area than a square or a 2:1 rectangle?\n",
    "\n",
    "Considering these options, the best dimensions for the maximum area are:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "929581a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Fourth branch: Start by visiting city D first, then C, then B, and finally A. Compare this route with the previous ones to determine if it offers any time or distance savings.\n",
      "\n",
      "5. Fifth branch: Start by visiting city A first, then C, then B, and finally D. Evaluate if this route provides any advantages over the other options in terms of efficiency.\n",
      "\n",
      "By exploring these different branches and variations, I will be able to determine the most efficient route to visit cities A, B, C, and D. I will consider factors such as distance, time, traffic conditions, and any other relevant variables to make an informed decision.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I need to plan the most efficient route to visit the following cities: A, B, C, and D. I'll explore different routes and their implications, step by step, to find the best option.\n",
    "\n",
    "1. First branch: Start by visiting city A, then move to city B, then to city C, and finally to city D. Consider the total distance and time required.\n",
    "\n",
    "2. Second branch: Start by visiting city B first, then A, then D, and finally C. Evaluate if this route is shorter or faster than the first.\n",
    "\n",
    "3. Third branch: Start by visiting city C first, then D, then A, and finally B. Analyze if this route offers any advantages over the others.\n",
    "\n",
    "At each step, I'll compare the results of each branch and see which provides the most efficient route. If needed, I will explore sub-branches by adjusting the sequence slightly.\n",
    "\n",
    "Let's see which path is the most optimal.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a06fe6",
   "metadata": {},
   "source": [
    "# Using Jinja2 Template Format__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d333b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "jinja2_template = \"Give me a {{ adjective }} fact about {{ topic }}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55997278",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a97f216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a interesting fact about space exploration\n"
     ]
    }
   ],
   "source": [
    "question = prompt.format(adjective=\"interesting\", topic=\"space exploration\")\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5171bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "The farthest spacecraft from Earth is Voyager 1, which was launched in 1977 and is currently over 14 billion miles away from Earth. It is the only human-made object to have entered interstellar space, beyond our solar system.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(question)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83b0f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Investing in renewable energy is crucial for governments in the next decade for several reasons. \n",
      "\n",
      "First and foremost, renewable energy sources such as solar, wind, and hydro power are sustainable and environmentally friendly alternatives to fossil fuels. As the effects of climate change become increasingly severe, it is imperative that governments take action to reduce greenhouse gas emissions and transition to cleaner energy sources. Investing in renewable energy will help to mitigate the impacts of climate change and protect the planet for future generations.\n",
      "\n",
      "Additionally, investing in renewable energy can create jobs and stimulate economic growth. The renewable energy sector is one of the fastest growing industries in the world, and governments that prioritize renewable energy development can attract investment, create new jobs, and boost local economies. By investing in renewable energy, governments can also reduce their dependence on imported fossil fuels, which can help to improve energy security and reduce the risk of supply disruptions.\n",
      "\n",
      "Furthermore, investing in renewable energy can help to diversify the energy mix and reduce the volatility of energy prices. Fossil fuel prices are notoriously volatile, and governments that rely heavily on fossil fuels are vulnerable to price fluctuations and supply disruptions. By investing in renewable energy, governments can reduce their exposure to these risks and create a more stable and secure energy system.\n",
      "\n",
      "In conclusion, investing in renewable energy is not only important for addressing climate change and protecting the environment, but also for creating jobs, stimulating economic growth, and improving energy security. Governments that prioritize renewable energy development in the next decade will be better positioned to meet the challenges of the future and build a more sustainable and resilient energy system.\n"
     ]
    }
   ],
   "source": [
    "jinja2_template = \"Make a convincing argument for why {{ action }} is important for {{ group }} in {{ time_period }}.\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "# Format the prompt with specific values for 'action', 'group', and 'time_period'\n",
    "argument_prompt = prompt.format(action=\"investing in renewable energy\", group=\"governments\", time_period=\"the next decade\")\n",
    "\n",
    "response = get_completion(argument_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4f9df3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Investing in renewable energy is crucial for governments in the next decade to combat climate change, reduce dependence on fossil fuels, create jobs in the growing green economy, and ensure energy security. Transitioning to clean energy sources will also lead to improved public health and a more sustainable future for all.\n"
     ]
    }
   ],
   "source": [
    "jinja2_template = \"In 50 words or less, Make a convincing argument for why {{ action }} is important for {{ group }} in {{ time_period }}.\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "\n",
    "# Format the prompt with specific values for 'action', 'group', and 'time_period'\n",
    "argument_prompt = prompt.format(action=\"investing in renewable energy\", group=\"governments\", time_period=\"the next decade\")\n",
    "\n",
    "response = get_completion(argument_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc47794",
   "metadata": {},
   "source": [
    "# Creating a Custom Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e985c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from pydantic import BaseModel, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38f5f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\\\n",
    "Given the book title, generate a brief summary of the book.\n",
    "Book Title: {book_title}\n",
    "Summary:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "415efbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the book title, generate a brief summary of the book.\n",
      "Book Title: The Great Gatsby\n",
      "Summary:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "\n",
    "class StringPromptTemplate:\n",
    "    def __init__(self, template):\n",
    "        self.template = template\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "class BookSummarizerPrompt(BaseModel):\n",
    "    book_title: str\n",
    "    template: StringPromptTemplate\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def create_prompt(self):\n",
    "        return self.template.format(book_title=self.book_title)\n",
    "\n",
    "# Assuming an instance of StringPromptTemplate is created elsewhere\n",
    "template = StringPromptTemplate(\n",
    "    \"\"\"\\\n",
    "Given the book title, generate a brief summary of the book.\n",
    "Book Title: {book_title}\n",
    "Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Usage\n",
    "book_summarizer_prompt = BookSummarizerPrompt(book_title=\"The Great Gatsby\", template=template)\n",
    "print(book_summarizer_prompt.create_prompt())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e8b50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "\"The Great Gatsby\" follows the story of Jay Gatsby, a wealthy and mysterious man who throws extravagant parties in the hopes of winning back his lost love, Daisy Buchanan. Set in the 1920s, the novel explores themes of love, wealth, and the American Dream, as Gatsby's obsession with Daisy ultimately leads to tragedy. Through the eyes of narrator Nick Carraway, readers are taken on a journey through the glamorous and corrupt world of the Jazz Age.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(book_summarizer_prompt.create_prompt())\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2482841",
   "metadata": {},
   "source": [
    "# String Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ba834b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short story about a brave knight who discovers a magic sword in enchanted forest.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a simple string template with placeholders\n",
    "template_str = \"Write a short story about a {character} who discovers a {object} in {location}.\"\n",
    "\n",
    "# Create a PromptTemplate object with the template string and a list of input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"object\", \"location\"],\n",
    "    template=template_str\n",
    ")\n",
    "\n",
    "# Format the prompt by filling in the placeholders with specific values\n",
    "formatted_prompt = prompt.format(character=\"brave knight\", object=\"magic sword\", location=\"enchanted forest\")\n",
    "\n",
    "# Print the formatted prompt\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9851ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:\n",
      "Sir William was known throughout the kingdom as the bravest and most skilled knight in all the land. He had faced countless foes and emerged victorious every time, earning him the title of the King's Champion. But even he had never encountered anything quite like the enchanted forest that lay on the outskirts of the kingdom.\n",
      "\n",
      "Rumors had long circulated about the forest, tales of strange creatures and powerful magic that could ensnare even the most seasoned warrior. But Sir William was undaunted, his courage and determination driving him forward as he ventured into the dark and twisted trees.\n",
      "\n",
      "As he made his way deeper into the forest, the air grew thick with an otherworldly energy, and the trees seemed to whisper secrets to him. It was then that he stumbled upon a clearing, where a magnificent sword lay embedded in a stone pedestal, shimmering with an ethereal light.\n",
      "\n",
      "Intrigued, Sir William approached the sword, his hand reaching out to touch the hilt. As soon as his fingers made contact, a surge of power coursed through him, filling him with a newfound strength and clarity of purpose. He knew then that this was no ordinary sword, but a weapon of great magic, forged by the ancient beings that dwelled within the forest.\n",
      "\n",
      "With the sword in hand, Sir William felt invincible, his every strike swift and true as he battled his way through the forest, facing down creatures of darkness and overcoming every obstacle in his path. And as he emerged from the enchanted forest, victorious and unscathed, he knew that he had been chosen for a greater destiny, to wield the magic sword and protect the kingdom from any threat that dared to challenge it.\n",
      "\n",
      "From that day on, Sir William was known not only as the King's Champion, but as the Swordbearer, a hero whose name would be remembered for generations to come. And as he rode off into the sunset, the magic sword gleaming in the fading light, he knew that he had truly become a legend in his own right.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(formatted_prompt)\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90478a6a",
   "metadata": {},
   "source": [
    "# Few Shot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d617f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 9, 13, 17, 21, 25, 29\n",
      "Sum: 114\n",
      "Answer: Even\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Task:\n",
    "You're provided with sequences of odd numbers. Your task is to determine if the sum of the numbers in each sequence results in an even number. If the sum is even, respond with \"Even.\" If the sum is odd, respond with \"Odd.\"\n",
    "\n",
    "Examples:\n",
    "\n",
    "Sequence: 3, 7, 15, 21, 8, 11, 4\n",
    "Sum: 69\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 5, 12, 19, 25, 10, 13, 3\n",
    "Sum: 87\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 6, 14, 21, 9, 11, 17, 7\n",
    "Sum: 85\n",
    "Answer: Odd\n",
    "\n",
    "Sequence: 8, 16, 24, 10, 13, 18, 5\n",
    "Sum: 94\n",
    "Answer: Even\n",
    "\n",
    "Sequence: 15, 32, 5, 13, 27, 7, 1\n",
    "Sum: 100\n",
    "Answer: Even\n",
    "\n",
    "New Sequence:\n",
    "Sequence: 9, 13, 17, 21, 25, 29\n",
    "Sum:\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237c21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
